{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ce8e7e-240b-4377-b1d2-72dac17f629a",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics : AUC-ROC\n",
    "AUC stands for Area Under Curve & ROC for Receiving Operator Characteristics\n",
    "ROC is a evaluation metric for binary classification tasks which is represented in the form of a curve, which me use the AUC to value.\n",
    "It computes the amount of True positives in fonction of the false positives.\n",
    "\n",
    "You can easily vizualize that a perfect model will give a square of side 1 and AUC of 1 which means that there are never false positives.\n",
    "![Perfect](https://developers.google.com/static/machine-learning/crash-course/images/auc_1-0.png)\n",
    "The AUC-ROC represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative.\n",
    "\n",
    "An Random model will gave a straight line from (0,0) to (1,1) \n",
    "![Random](https://developers.google.com/static/machine-learning/crash-course/images/auc_0-5.png)\n",
    "\n",
    "A good model will have a curve somewhat looking like : \n",
    "![GoodModel](https://developers.google.com/static/machine-learning/crash-course/images/auc_0-93.png)\n",
    "Which we can read as when there is no true positives : the model will not predict false positives => meaning that all datapoints are negatives.\n",
    "\n",
    "A condition for this is that the model is roughly balanced.\n",
    "It's important to see the error rate of your model in a glimpse of an eye.\n",
    "\n",
    "For imbalanced datasets you can compute precision-recall curve that'll give you a similar outview.\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c7ee5-c039-43b2-87ec-e2ec3dff4abe",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Datasets : \n",
    "\n",
    "## Oversampling\n",
    "Oversampling provides a method to rebalance classes before model training commences. By replicating minority class data points, oversampling balances the playing field and prevents algorithms from disregarding significant yet sparse classes.\n",
    "You can use random oversampling which just duplicates datapoints, or SMOTE (Synthetic Minority Oversampling Technique), and ADASYN (Adaptive Synthetic Sampling Approach for Imbalanced Learning) to strategically generate new data points in that class.\n",
    "You can also use data augmentation techniques, such as image rotations in case of image classifications, replacement by synonyms in text etc\n",
    "![Oversampling](https://miro.medium.com/v2/resize:fit:720/format:webp/0*HWTiFVseEi0CNFg_.png)\n",
    "## Undersampling\n",
    "It's the opposite somewhat of oversampling.\n",
    "Balance uneven datasets by keeping all of the data in the minority class and decreasing the size of the majority class.  Though it has disadvantages, such as the loss of potentially important information\n",
    "## F1-Score\n",
    "In imbalanced case you have to pay attention to your F1 score. \n",
    "Why : it's the harmonic mean between precision and recall : 2 / (1/precision + 1/recall) = 2 * (precision*recalll) / (precision + recall)\n",
    "\n",
    "if precision and recall are both high, meaning close to 1 you can interpret it two ways :\n",
    "- your fp and fn rates are low meaning that your model is not, in case of imbalance, just rendering the most present class\n",
    "- your F1-Score is also close to 1\n",
    "\n",
    "If the model just returns the most present class, one of the precision or recall will drop causing F1 to drop.\n",
    "What's the threshold for high/low : the ratio of the most present class (with no resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdcd463-f358-40c2-a1fa-47597c150e26",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Feature engineering is a technique that leverages data to create new features that are not initially in the training set.\n",
    "These new features are a combinaison or function of previous features. It's goal is to make data richer, clearer and easily usable for the defined model to improve accuracy and robustness. It also lowers the complexity of the model as it already exposes some realationships between the input features that could've been complex to find. For instance in timeseries, we can introduce variance over a fixed time as a new feature. Removing or capping outliers is another example as well.\n",
    "\n",
    "feature engineering can often have a more significant impact on model performance than the choice of the model itself\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "Once you've enhanced your training data, you have to select the features that most make sense to your view to avoid giving useless information to your model and start causing overfitting. This involve­s selectively including or e­xcluding important features while ke­eping them unchanged. By doing so, it e­ffectively eliminate­s irrelevant noise from your data and re­duces the size and scope of the­ input dataset.\n",
    "\n",
    "Feature selection can also be automated with :\n",
    "- filter methods : They offer computational efficie­ncy and effectivene­ss in eliminating duplicate, correlate­d, and unnecessary feature­s.\n",
    "- wrapper methods : Train the mode­l iteratively using differe­nt subsets of features. The­y determine the­ model’s performance and add or re­move features accordingly. These model are computationally greedy.\n",
    "- embedded methods : that combines the advantages of the two above by integrating feature se­lection directly into the le­arning algorithm itself. These me­thods are computationally efficient and conside­r feature combinations, making them e­ffective in solving complex proble­ms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53180ef-6b73-4321-a166-fb25e8088726",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Feature selection is a hyperparameter for instance : do I choose regularization L1 or L2 or do I go for tree based models\n",
    "## Hyperparameter\n",
    "Your learning model has parameters that are modified during the learning phase and parameters that are not.\n",
    "The latter are known as hyperparameter : all the variables that you set for your model to train on:\n",
    "- which evaluation metric\n",
    "- early stopping\n",
    "- which model\n",
    "- batch_size\n",
    "- tree depth and number of estimators for tree based models\n",
    "- thresholds in probability to decide the class output\n",
    "\n",
    "Hyperparameter tuning consist of finding the right combination of hyperparameters that maximizes the accuracy at the end.\n",
    "This can be manually or automatically with methods such as GridSearch or RandomSearch that will train iteratively your model with different combination of hyperparameters that you provided to find the optimal set that maximizes the accuracy of the model.\n",
    "This can be greedy computationally during the search but can be worth it . The data scientist must make sure that he understans and fell wonfident with the final combination before using it : the reason must not be just because."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fe3f9-fbe0-45d8-a5bb-b2bc276245ce",
   "metadata": {},
   "source": [
    "# The titanic survical \n",
    "\n",
    "Before the EDA we can foresee that the dataset will be imbalanced so we'll need to handle that. Being in a binary classification taks : the metrics are going to be important : precision, recall, f1 and the AUC-ROC to judge the accuracy of the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
